# show-builder.js — Audio Analysis and Choreography Generation

`show-builder.js` is the bridge between a raw audio file and a choreographed show timeline. It exposes a single global function:

```js
const show = await window.buildShowWithPython(
  audioBuffer,
  band,
  title,
  durationMs,
);
// returns a parsed .cybershow.json v3.0 object
```

All the heavy lifting — audio analysis, beat detection, frequency-band splitting, and movement assignment — happens inside Python via Pyodide. The JavaScript side only handles:

1. Audio pre-processing (mix to mono, decimate to 11,025 Hz)
2. Pyodide loading and lifecycle management
3. Passing data in and receiving the JSON result

---

## Why Python in the Browser?

The Show Analysis Module (SAM) was written in Python because:

- NumPy's vectorised array operations make the boxcar-filter frequency analysis fast and readable; equivalent manual JS would be substantially more complex to write and maintain
- The SAM logic is reused server-side and in offline testing without modification
- Pyodide allows the exact same Python code to run in the browser and in CPython

The trade-off is a ~30 MB Pyodide WASM download on first use. This is cached aggressively by the browser after the first load.

---

## Audio Pre-Processing

Before Python sees any audio data, JavaScript does two steps:

### 1. Mix to Mono

All audio channels are averaged into a single `Float32Array`. This is correct for music analysis — we want loudness/onset information, not stereo positioning.

### 2. Decimate to 11,025 Hz

The original 44,100 Hz signal is downsampled by a factor of 4 using a **box-filter averager** (not a simple skip-sample). The averaging prevents aliasing that would corrupt the onset detection. 11,025 Hz is sufficient for the frequency analysis SAM performs (well above the Nyquist for the highest frequency band).

Result: a mono `Int16Array` at 11,025 Hz. This is 4× cheaper to process than full-rate audio, which matters inside Pyodide where WASM performance is slower than native CPython.

---

## Pyodide Lifecycle

The module maintains a **singleton promise** (`_pyodideReady`) so Pyodide is only loaded once per page session regardless of how many shows are built.

### Reuse strategy

```
Does window._svizPyodide exist? (SViz already loaded it)
  → Attach SAM bridge to the existing instance (no second WASM download)

Is window._svizPyodidePromise pending?
  → Wait for SViz to finish loading, then attach to that instance

Otherwise:
  → Load Pyodide fresh, inject SAM bridge
```

This is critical for page performance. Without sharing, every export or analysis operation would re-download 30 MB of WASM.

### SAM Bridge Injection

Once a Pyodide instance is ready, the bridge script (`SCME/SAM/show_bridge.py`) is fetched over HTTP (`fetch(BRIDGE_PATH)`) and run via `py.runPython(src)`. A flag `py._samBridgeLoaded` prevents re-injection on subsequent calls.

---

## Python Function Called

```python
analyze_and_choreograph_json(
    samples_list,   # list[int]  — mono Int16, 11025 Hz
    sample_rate,    # int        — 11025
    band,           # str        — "rock" or "munch"
    title,          # str        — show title
    duration_ms,    # int        — original audio duration in ms
) -> str            # JSON string (.cybershow.json v3.0)
```

This function lives in `SCME/SAM/show_bridge.py`. It:

1. Splits the audio into bass, mid, and treble energy bands using boxcar (moving-average) filters — no FFT
2. Computes onset-strength curves per band (per-chunk energy increase)
3. Picks beat peaks from a combined onset curve; picks treble peaks separately for vocalist cues
4. Estimates BPM from the **median inter-onset interval** of the detected beats
5. Maps each beat to character movements using per-character role tables (`_ROCK` or `_MUNCH`); vocalists also receive soft idle movements on treble-only onsets between beats
6. Returns a fully-formed `.cybershow.json` v3.0 string

---

## Return Value

The JSON is parsed in JavaScript and stored as the current show. Its structure:

```json
{
  "cyberstar_show": true,
  "version": "3.0",
  "title": "Come Together",
  "band": "rock",
  "duration_ms": 256000,
  "duration_frames": 12800,
  "fps": 50,
  "bpm": 84,
  "description": "Auto-generated by SAM",
  "characters": {
    "Rolfe": {
      "signals": [
        {"frame": 50, "movement": "mouth", "state": true, "note": ""},
        {"frame": 53, "movement": "mouth", "state": false, "note": ""},
        ...
      ]
    },
    ...
  }
}
```

The `fps` in the JSON is always 50 (internal show format). This is separate from the BMC frame rate of 45.9375 fps used on the signal tracks.
